{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4496478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gel_data_generator.py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "\n",
    "class GelColumnRunGenerator:\n",
    "    def __init__(self, config=None):\n",
    "        self.config = config or {\n",
    "            'run_duration_hrs': {'min': 4, 'max': 12},  # Hours per column run\n",
    "            'batches_per_run': {'min': 3, 'max': 8},    # Batches per run\n",
    "            'batch_duration_mins': {'min': 30, 'max': 120},  # Minutes per batch\n",
    "            'degradation_per_run': 0.02,  # Gel score increase per run\n",
    "            'pressure_noise': 0.5,        # Measurement noise\n",
    "            'run_break_hours': {'min': 1, 'max': 4}  # Downtime between runs\n",
    "        }\n",
    "        \n",
    "    def generate_run_schedule(self, total_days=30):\n",
    "        \"\"\"Generate realistic column run schedule\"\"\"\n",
    "        runs = []\n",
    "        current_time = datetime(2024, 1, 1, 8, 0)  # Start at 8 AM\n",
    "        \n",
    "        run_id = 1\n",
    "        while current_time.date() <= datetime(2024, 1, 1).date() + timedelta(days=total_days):\n",
    "            # Determine run characteristics\n",
    "            run_duration = random.uniform(\n",
    "                self.config['run_duration_hrs']['min'],\n",
    "                self.config['run_duration_hrs']['max']\n",
    "            )\n",
    "            \n",
    "            n_batches = random.randint(\n",
    "                self.config['batches_per_run']['min'],\n",
    "                self.config['batches_per_run']['max']\n",
    "            )\n",
    "            \n",
    "            # Create run\n",
    "            run_end = current_time + timedelta(hours=run_duration)\n",
    "            runs.append({\n",
    "                'run_id': run_id,\n",
    "                'start_time': current_time,\n",
    "                'end_time': run_end,\n",
    "                'duration_hrs': run_duration,\n",
    "                'n_batches': n_batches,\n",
    "                'status': 'planned'\n",
    "            })\n",
    "            \n",
    "            # Downtime between runs\n",
    "            downtime = random.uniform(\n",
    "                self.config['run_break_hours']['min'],\n",
    "                self.config['run_break_hours']['max']\n",
    "            )\n",
    "            \n",
    "            current_time = run_end + timedelta(hours=downtime)\n",
    "            \n",
    "            # Don't start runs late at night\n",
    "            if current_time.hour > 20:  # After 8 PM\n",
    "                # Move to next morning\n",
    "                next_day = current_time.date() + timedelta(days=1)\n",
    "                current_time = datetime(next_day.year, next_day.month, next_day.day, 8, 0)\n",
    "            \n",
    "            run_id += 1\n",
    "        \n",
    "        return pd.DataFrame(runs)\n",
    "    \n",
    "    def generate_batch_level_data(self, run_schedule):\n",
    "        \"\"\"Generate data at batch level within runs\"\"\"\n",
    "        all_batches = []\n",
    "        batch_counter = 1\n",
    "        \n",
    "        for _, run in run_schedule.iterrows():\n",
    "            # Base gel degradation for this run (increases with each run)\n",
    "            base_gel_score = min(0.1 + (run['run_id'] - 1) * self.config['degradation_per_run'], 0.95)\n",
    "            \n",
    "            # Generate batches within this run\n",
    "            batch_durations = np.random.uniform(\n",
    "                self.config['batch_duration_mins']['min'],\n",
    "                self.config['batch_duration_mins']['max'],\n",
    "                size=int(run['n_batches'])\n",
    "            )\n",
    "            \n",
    "            # Ensure batches fit within run duration\n",
    "            total_batch_mins = sum(batch_durations)\n",
    "            scaling_factor = (run['duration_hrs'] * 60) / total_batch_mins\n",
    "            batch_durations = batch_durations * scaling_factor\n",
    "            \n",
    "            current_batch_start = run['start_time']\n",
    "            \n",
    "            for batch_idx in range(int(run['n_batches'])):\n",
    "                batch_duration = batch_durations[batch_idx]\n",
    "                batch_end = current_batch_start + timedelta(minutes=batch_duration)\n",
    "                \n",
    "                # Generate batch-level metrics\n",
    "                batch_data = self._generate_batch_metrics(\n",
    "                    batch_counter,\n",
    "                    run['run_id'],\n",
    "                    batch_idx,\n",
    "                    current_batch_start,\n",
    "                    batch_end,\n",
    "                    base_gel_score\n",
    "                )\n",
    "                \n",
    "                all_batches.append(batch_data)\n",
    "                current_batch_start = batch_end\n",
    "                batch_counter += 1\n",
    "        \n",
    "        return pd.DataFrame(all_batches)\n",
    "    \n",
    "    def _generate_batch_metrics(self, batch_id, run_id, batch_idx, start_time, end_time, base_gel_score):\n",
    "        \"\"\"Generate detailed metrics for a single batch\"\"\"\n",
    "        duration_minutes = (end_time - start_time).total_seconds() / 60\n",
    "        \n",
    "        # Gel degradation increases slightly within batch\n",
    "        batch_gel_start = base_gel_score + (batch_idx * 0.005)\n",
    "        batch_gel_end = batch_gel_start + 0.01  # Minor degradation during batch\n",
    "        \n",
    "        # Simulate pressure profiles during batch\n",
    "        time_points = max(5, int(duration_minutes // 15))  # Sample every 15 minutes\n",
    "        timestamps = pd.date_range(start=start_time, end=end_time, periods=time_points)\n",
    "        \n",
    "        # Pressure trends - typically stable with minor fluctuations\n",
    "        elution_pressure = 12 + (batch_gel_start * 8)  # Increases with gel degradation\n",
    "        flow_pressure = 6 + (batch_gel_start * 4)\n",
    "        \n",
    "        # Add batch phase effects\n",
    "        if batch_idx == 0:  # First batch might have priming effects\n",
    "            elution_pressure += 2\n",
    "        elif batch_idx > 5:  # Later batches show more degradation\n",
    "            elution_pressure += 1\n",
    "        \n",
    "        # Add random noise\n",
    "        elution_pressure += np.random.normal(0, self.config['pressure_noise'])\n",
    "        flow_pressure += np.random.normal(0, self.config['pressure_noise'] * 0.5)\n",
    "        \n",
    "        # Column age effect (older columns show higher pressure)\n",
    "        column_age_factor = min(run_id / 100, 0.3)  # Up to 30% increase over 100 runs\n",
    "        elution_pressure *= (1 + column_age_factor)\n",
    "        flow_pressure *= (1 + column_age_factor * 0.7)\n",
    "        \n",
    "        # Calculate batch-level average gel score\n",
    "        batch_gel_score = (batch_gel_start + batch_gel_end) / 2\n",
    "        \n",
    "        return {\n",
    "            'batch_id': batch_id,\n",
    "            'run_id': run_id,\n",
    "            'batch_in_run': batch_idx + 1,\n",
    "            'start_time': start_time,\n",
    "            'end_time': end_time,\n",
    "            'duration_minutes': duration_minutes,\n",
    "            'gel_score': batch_gel_score,\n",
    "            'elution_pressure_avg': elution_pressure,\n",
    "            'flow_pressure_avg': flow_pressure,\n",
    "            'column_runs_completed': run_id - 1,  # Runs before this one\n",
    "            'column_age_factor': column_age_factor,\n",
    "            'phase': 'loading' if batch_idx == 0 else 'elution'\n",
    "        }\n",
    "    \n",
    "    def generate_high_resolution_data(self, batch_data, samples_per_batch=10):\n",
    "        \"\"\"Generate high-resolution time series within batches\"\"\"\n",
    "        high_res_records = []\n",
    "        \n",
    "        for _, batch in batch_data.iterrows():\n",
    "            # Create time points within this batch\n",
    "            time_points = pd.date_range(\n",
    "                start=batch['start_time'],\n",
    "                end=batch['end_time'],\n",
    "                periods=samples_per_batch\n",
    "            )\n",
    "            \n",
    "            # Simulate pressure fluctuations during batch\n",
    "            time_fraction = np.linspace(0, 1, samples_per_batch)\n",
    "            \n",
    "            # Base pressure with gradual increase during batch\n",
    "            pressure_trend = batch['elution_pressure_avg'] + (time_fraction * 0.5)\n",
    "            \n",
    "            # Add operational noise (pump fluctuations, etc.)\n",
    "            operational_noise = np.random.normal(0, 0.3, samples_per_batch)\n",
    "            \n",
    "            # Add periodic effects (pump cycles every ~2 minutes)\n",
    "            if batch['duration_minutes'] > 2:\n",
    "                pump_cycle = 0.2 * np.sin(2 * np.pi * time_fraction * \n",
    "                                         (batch['duration_minutes'] / 2))\n",
    "            else:\n",
    "                pump_cycle = 0\n",
    "            \n",
    "            elution_pressure = pressure_trend + operational_noise + pump_cycle\n",
    "            flow_pressure = batch['flow_pressure_avg'] * 0.5 + operational_noise * 0.3\n",
    "            \n",
    "            # Gel degradation increases slightly during batch\n",
    "            gel_score = batch['gel_score'] + (time_fraction * 0.005)\n",
    "            \n",
    "            for i, timestamp in enumerate(time_points):\n",
    "                high_res_records.append({\n",
    "                    'timestamp': timestamp,\n",
    "                    'run_id': batch['run_id'],\n",
    "                    'batch_id': batch['batch_id'],\n",
    "                    'batch_in_run': batch['batch_in_run'],\n",
    "                    'elution_pressure': elution_pressure[i],\n",
    "                    'flow_pressure': flow_pressure[i],\n",
    "                    'gel_score': min(gel_score[i], 1.0),\n",
    "                    'column_runs': batch['column_runs_completed'],\n",
    "                    'is_operational': 1,\n",
    "                    'phase': 'elution' if time_fraction[i] > 0.2 else 'loading'\n",
    "                })\n",
    "        \n",
    "        df = pd.DataFrame(high_res_records)\n",
    "        \n",
    "        # Add anomalies\n",
    "        df = self._add_anomalies(df, anomaly_rate=0.02)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def _add_anomalies(self, df, anomaly_rate=0.02):\n",
    "        \"\"\"Add realistic anomalies to the data\"\"\"\n",
    "        n_anomalies = int(len(df) * anomaly_rate)\n",
    "        anomaly_indices = np.random.choice(len(df), n_anomalies, replace=False)\n",
    "        \n",
    "        df['anomaly'] = 0\n",
    "        df['anomaly_type'] = 'none'\n",
    "        \n",
    "        anomaly_types = [\n",
    "            'pressure_spike',\n",
    "            'pressure_drop', \n",
    "            'gradual_drift',\n",
    "            'stuck_value'\n",
    "        ]\n",
    "        \n",
    "        for idx in anomaly_indices:\n",
    "            anomaly_type = random.choice(anomaly_types)\n",
    "            \n",
    "            if anomaly_type == 'pressure_spike':\n",
    "                df.loc[idx, 'elution_pressure'] *= 1.5  # 50% spike\n",
    "                df.loc[idx, 'gel_score'] = min(df.loc[idx, 'gel_score'] + 0.1, 1.0)\n",
    "                \n",
    "            elif anomaly_type == 'pressure_drop':\n",
    "                df.loc[idx, 'elution_pressure'] *= 0.7  # 30% drop\n",
    "                \n",
    "            elif anomaly_type == 'gradual_drift':\n",
    "                # Affects this and next 5 samples\n",
    "                for j in range(min(6, len(df) - idx)):\n",
    "                    drift = 1 + (0.05 * (j + 1))\n",
    "                    df.loc[idx + j, 'elution_pressure'] *= drift\n",
    "                    df.loc[idx + j, 'gel_score'] = min(\n",
    "                        df.loc[idx + j, 'gel_score'] + (0.02 * (j + 1)), \n",
    "                        1.0\n",
    "                    )\n",
    "                    df.loc[idx + j, 'anomaly'] = 1\n",
    "                    df.loc[idx + j, 'anomaly_type'] = 'gradual_drift'\n",
    "                continue\n",
    "                \n",
    "            elif anomaly_type == 'stuck_value':\n",
    "                # Value gets stuck for several readings\n",
    "                stuck_value = df.loc[idx, 'elution_pressure']\n",
    "                for j in range(min(4, len(df) - idx)):\n",
    "                    df.loc[idx + j, 'elution_pressure'] = stuck_value\n",
    "                    df.loc[idx + j, 'anomaly'] = 1\n",
    "                    df.loc[idx + j, 'anomaly_type'] = 'stuck_value'\n",
    "                continue\n",
    "            \n",
    "            df.loc[idx, 'anomaly'] = 1\n",
    "            df.loc[idx, 'anomaly_type'] = anomaly_type\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def generate_complete_dataset(self, total_days=30, resolution='high'):\n",
    "        \"\"\"Generate complete dataset with column run hierarchy\"\"\"\n",
    "        print(\"Generating column run schedule...\")\n",
    "        run_schedule = self.generate_run_schedule(total_days)\n",
    "        \n",
    "        print(f\"Generated {len(run_schedule)} column runs\")\n",
    "        print(f\"Total operational hours: {run_schedule['duration_hrs'].sum():.1f}\")\n",
    "        \n",
    "        print(\"\\nGenerating batch-level data...\")\n",
    "        batch_data = self.generate_batch_level_data(run_schedule)\n",
    "        \n",
    "        print(f\"Generated {len(batch_data)} batches\")\n",
    "        print(f\"Average batches per run: {batch_data.groupby('run_id').size().mean():.1f}\")\n",
    "        \n",
    "        if resolution == 'high':\n",
    "            print(\"\\nGenerating high-resolution time series...\")\n",
    "            time_series_data = self.generate_high_resolution_data(batch_data)\n",
    "            print(f\"Generated {len(time_series_data)} time points\")\n",
    "            return {\n",
    "                'run_schedule': run_schedule,\n",
    "                'batch_data': batch_data,\n",
    "                'time_series': time_series_data\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                'run_schedule': run_schedule,\n",
    "                'batch_data': batch_data\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5726f9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gel_data_generator'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# main.py\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgel_data_generator\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GelColumnRunGenerator\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'gel_data_generator'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85786e17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>gel_score</th>\n",
       "      <th>elution_pressure</th>\n",
       "      <th>flow_pressure</th>\n",
       "      <th>column_runs</th>\n",
       "      <th>anomaly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-01-01 00:00:00</td>\n",
       "      <td>0.091802</td>\n",
       "      <td>9.983162</td>\n",
       "      <td>5.248398</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-01-01 00:15:00</td>\n",
       "      <td>0.088615</td>\n",
       "      <td>11.431219</td>\n",
       "      <td>4.598737</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-01-01 00:30:00</td>\n",
       "      <td>0.067050</td>\n",
       "      <td>10.941074</td>\n",
       "      <td>5.015491</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-01-01 00:45:00</td>\n",
       "      <td>0.046035</td>\n",
       "      <td>10.515478</td>\n",
       "      <td>5.527602</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-01-01 01:00:00</td>\n",
       "      <td>0.158832</td>\n",
       "      <td>9.112687</td>\n",
       "      <td>5.781643</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            timestamp  gel_score  elution_pressure  flow_pressure  \\\n",
       "0 2024-01-01 00:00:00   0.091802          9.983162       5.248398   \n",
       "1 2024-01-01 00:15:00   0.088615         11.431219       4.598737   \n",
       "2 2024-01-01 00:30:00   0.067050         10.941074       5.015491   \n",
       "3 2024-01-01 00:45:00   0.046035         10.515478       5.527602   \n",
       "4 2024-01-01 01:00:00   0.158832          9.112687       5.781643   \n",
       "\n",
       "   column_runs  anomaly  \n",
       "0            2        0  \n",
       "1            3        0  \n",
       "2            7        0  \n",
       "3            9        0  \n",
       "4           11        0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411d8d98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
